{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression:\n",
    "    \n",
    "    def __init__(self, feat_dims=0):\n",
    "        # alpha is weight decay hyperparameter\n",
    "        \n",
    "        self.learning_rate = 0.00001\n",
    "        self.epochs = 100\n",
    "        self.batch_size = 100\n",
    "        \n",
    "        self.feat_dims = feat_dims\n",
    "        self.output_classes = 1\n",
    "        \n",
    "        # create weights array/matrix size (num features x output)\n",
    "        self.weights = 0.001 * np.random.rand(self.feat_dims, self.output_classes)\n",
    "        self.alpha = 0.2  # regularization strength\n",
    "        \n",
    "        self.y_mean = None\n",
    "        \n",
    "    def normalize_feat(self, x, mean=None, std=None):\n",
    "        # normalize the feature data.  test data must pass mean and std\n",
    "        \n",
    "        # calc feature-wise mean\n",
    "        if mean is None:\n",
    "            mean = np.mean(x, axis=0)\n",
    "            \n",
    "        # calc feature-wise std\n",
    "        if std is None:\n",
    "            std = np.std(x, axis=0)\n",
    "        \n",
    "        # sub the mean per column\n",
    "        x_norm = x - mean\n",
    "\n",
    "        # div by the standard dev.\n",
    "        x_norm = x_norm / std\n",
    "\n",
    "        return x_norm, mean, std\n",
    "        \n",
    "    def load_data(self, fname, bias=1):\n",
    "        \n",
    "        data = loadtxt(fname, delimiter=',')\n",
    "        \n",
    "        # loads data, normalizes, and appends a bias vector to the data\n",
    "\n",
    "        TRAIN_NUM = 463714  # training data up to this point\n",
    "\n",
    "        # process training data\n",
    "        x_train = data[:TRAIN_NUM,1:].astype(float)  # parse train\n",
    "        \n",
    "#         print('x before norm: ', x_train[0])\n",
    "        \n",
    "        x_train, train_mean, train_std = self.normalize_feat(x_train)  # normalize data\n",
    "\n",
    "        # create a col vector of ones\n",
    "        col_bias = np.ones((x_train.shape[0], 1))\n",
    "\n",
    "        # append bias with hstack\n",
    "        x_train = np.hstack((x_train, col_bias))\n",
    "        \n",
    "        # convert label vals to int and to vector\n",
    "        y_train = data[:TRAIN_NUM,0].astype(int)\n",
    "        y_train = y_train.reshape((-1, 1))\n",
    "\n",
    "        # -------------------\n",
    "        \n",
    "        # process test data\n",
    "        x_test = data[TRAIN_NUM:,1:].astype(float)  # parse test\n",
    "        x_test, _, _ = self.normalize_feat(x_test, train_mean, train_std)  # normalize data\n",
    "\n",
    "        # create a col vector of ones\n",
    "        col_bias = np.ones((x_test.shape[0], 1))\n",
    "\n",
    "        # append bias with hstack\n",
    "        x_test = np.hstack((x_test, col_bias))    \n",
    "\n",
    "        # convert label vals to int and to vector\n",
    "        y_test = data[TRAIN_NUM:,0].astype(int)\n",
    "        y_test = y_test.reshape((-1, 1))  # convert to column vector\n",
    "\n",
    "        \n",
    "        print('x after norm: ', x_train[:-1])\n",
    "        \n",
    "        \n",
    "        return x_train, y_train, x_test, y_test\n",
    "\n",
    "    def musicMSE(self, pred, gt):\n",
    "\n",
    "        # make sure to floor by converting to int()\n",
    "        diff = pred - gt\n",
    "        mse = (np.square(diff)).mean()\n",
    "\n",
    "        return mse\n",
    "    \n",
    "    def label_sub_mean(self, label):\n",
    "        \n",
    "        # find the mean\n",
    "        self.y_mean = np.mean(label)\n",
    "        \n",
    "        # sub mean\n",
    "        temp = label - self.y_mean\n",
    "        \n",
    "        return temp\n",
    "\n",
    "    def train_loss(self, x, yt_sm):\n",
    "        # calc the cost\n",
    "        # yt = true label, sub mean label\n",
    "        \n",
    "        n_samples = x.shape[0]        \n",
    "        pred_y = np.dot(x, self.weights)\n",
    "        residual = np.linalg.norm(pred_y - yt_sm, ord=2, axis=0) \n",
    "        sq_residual = np.square(residual)\n",
    "        \n",
    "        loss = (sq_residual / n_samples) + self.alpha * np.square( np.linalg.norm(self.weights, ord=2, axis=0) )\n",
    "    \n",
    "        return loss \n",
    "    \n",
    "    def test_loss(self, x, yt_sm):\n",
    "        # calc the cost at test time\n",
    "        # yt = true label, is regular label\n",
    "        \n",
    "        n_samples = x.shape[0]  \n",
    "        \n",
    "        # need to add the mean back to label\n",
    "        yt = yt_sm + self.y_mean\n",
    "        \n",
    "        # predict\n",
    "        pred_y = np.dot(x, self.weights)\n",
    "        \n",
    "        # need to add the y mean back\n",
    "        pred_y = pred_y + self.y_mean\n",
    "        \n",
    "        residual = np.linalg.norm(pred_y - yt, ord=2, axis=0) \n",
    "        sq_residual = np.square(residual)\n",
    "        \n",
    "        loss = (sq_residual / n_samples) + self.alpha * np.square( np.linalg.norm(self.weights, ord=2, axis=0) )\n",
    "    \n",
    "        return loss\n",
    "    \n",
    "    def gradient(self, x, yt_sm):\n",
    "        \n",
    "        n_samples = x.shape[0]\n",
    "        \n",
    "        pred_y = np.dot(x, self.weights)\n",
    "        residual = pred_y - yt_sm\n",
    "        dW = (np.dot(x.T, residual) / n_samples) + 2 * self.weights * self.alpha\n",
    "        \n",
    "        return dW\n",
    "\n",
    "    def calc_mse(self, x, y_sm):\n",
    "        # preprocesses and calls musicMSE\n",
    "        \n",
    "        # predict\n",
    "        pred_y = np.dot(x, self.weights)\n",
    "        \n",
    "        # add the y mean to the pred\n",
    "        pred_y += self.y_mean\n",
    "        \n",
    "        # add the y mean back to the labels\n",
    "        y_labels = y_sm + self.y_mean\n",
    "        \n",
    "        # calc the MSE\n",
    "        mse = self.musicMSE(pred_y, y_labels)\n",
    "        \n",
    "        print('MSE: ', mse)\n",
    "        \n",
    "        return mse, pred_y\n",
    "\n",
    "    def train_phase(self, x_train, y_train_sm):\n",
    "        # shuffle data together, and forward prop by batch size, and add momentum\n",
    "\n",
    "        num_train = x_train.shape[0]\n",
    "        losses = []\n",
    "        # Randomize the data (using sklearn shuffle)\n",
    "        x_train, y_train_sm = shuffle(x_train, y_train_sm)\n",
    "\n",
    "        # get the next batch (loop through number of training samples, step by batch size)\n",
    "        for i in range(0, num_train, self.batch_size):\n",
    "\n",
    "            # grab the next batch size\n",
    "            x_train_batch = x_train[i:i + self.batch_size]\n",
    "            y_train_batch_sm = y_train_sm[i:i + self.batch_size]\n",
    "\n",
    "            # calc loss\n",
    "            loss = self.train_loss(x_train_batch, y_train_batch_sm)\n",
    "            \n",
    "            dW = self.gradient(x_train_batch, y_train_batch_sm)\n",
    "            \n",
    "            self.weights -= dW * self.learning_rate  # update the weights\n",
    "            \n",
    "#             print('weights: ', self.weights)\n",
    "            \n",
    "            losses.append(loss)  # save the losses\n",
    "\n",
    "        return np.average(losses)  # return the average\n",
    "\n",
    "    def test_phase(self, x, y_sm):\n",
    "        # extra, but more explicit calc of loss and gradient during testing (no back prop)\n",
    "        \n",
    "        # calc loss\n",
    "        loss = self.test_loss(x, y_sm)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def run_epochs(self, x_train, y_train_sm, x_test, y_test_sm):\n",
    "        # start the training/valid by looping through epochs\n",
    "\n",
    "        # store losses and accuracies here\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        train_mse_arr = []\n",
    "        test_mse_arr = []\n",
    "\n",
    "        for e in range(self.epochs): # loop through epochs\n",
    "\n",
    "            print('Epoch {} / {}...'.format(e + 1, self.epochs))\n",
    "\n",
    "            # calc loss and accuracies\n",
    "            train_loss = self.train_phase(x_train, y_train_sm)\n",
    "            test_loss = self.test_phase(x_test, y_test_sm)\n",
    "            \n",
    "            train_mse, train_preds = self.calc_mse(x_train, y_train_sm)\n",
    "            test_mse, test_preds = self.calc_mse(x_test, y_test_sm)\n",
    "\n",
    "            # append vals to lists\n",
    "            train_losses.append(train_loss)\n",
    "            test_losses.append(test_loss)\n",
    "            train_mse_arr.append(train_mse)\n",
    "            test_mse_arr.append(test_mse)\n",
    "        \n",
    "#         return train_losses, test_losses\n",
    "\n",
    "        # return all the vals\n",
    "        return train_losses, test_losses, train_mse_arr, test_mse_arr, test_preds\n",
    "\n",
    "    def closed_form(self, x, yt):\n",
    "        # yt is regular labels\n",
    "        # returns the weights w that allow you to find the prediction\n",
    "\n",
    "        xt = np.transpose(x)\n",
    "        alpha_identity = self.alpha * np.identity(len(xt))\n",
    "\n",
    "\n",
    "        theInverse = np.linalg.inv(np.dot(xt, x) + alpha_identity)\n",
    "        w = np.dot(np.dot(theInverse, xt), yt)\n",
    "        return w\n",
    "    \n",
    "    \n",
    "    def plot_graph(self, train_losses, test_losses, train_mse, test_mse):\n",
    "        # plot graph\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(train_losses, label=\"Train loss\")\n",
    "        plt.plot(test_losses, label=\"Test loss\")\n",
    "        plt.legend(loc='best')\n",
    "        plt.title(\"Epochs vs. Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss (Cross entropy)\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(train_mse, label=\"Train MSE\")\n",
    "        plt.plot(test_mse, label=\"Test MSE\")\n",
    "        plt.legend(loc='best')\n",
    "        plt.title(\"Epochs vs MSE\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"MSE\")\n",
    "        plt.show()\n",
    "        # save plot \n",
    "        plt.savefig('./regression_loss_acc')\n",
    "\n",
    "    def make_mesh_grid(self, x, y, h=0.02):\n",
    "        # make a mesh grid for the decision boundary\n",
    "        \n",
    "        x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n",
    "        y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
    "        x_x, y_y = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "        return x_x, y_y  # matrix of x-axis and y-axis\n",
    "\n",
    "    def plot_contours(self, plt, x_x, y_y, **params):\n",
    "        # plot contours    \n",
    "\n",
    "        array = np.array([x_x.ravel(), y_y.ravel()])\n",
    "        f = np.dot(array.T, self.weights)\n",
    "        prob = self.softmax(f)\n",
    "        Q = np.argmax(prob, axis=1) + 1\n",
    "        Q = Q.reshape(x_x.shape)\n",
    "        plt.contourf(x_x, y_y, Q, **params)  # takes in variable number of params\n",
    "\n",
    "    def plot_decision_boundary(self, x, y):\n",
    "        # plot decision boundary\n",
    "\n",
    "        markers = ('o', '.', 'x')\n",
    "        colors = ('yellow', 'grey', 'green')\n",
    "        cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "        x_x, y_y = self.make_mesh_grid(x, y)\n",
    "        self.plot_contours(plt, x_x, y_y, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "        \n",
    "        # plot training points\n",
    "        for idx, cl in enumerate(np.unique(y)):\n",
    "            xBasedOnLabel = x[np.where(y[:,0] == cl)]\n",
    "            plt.scatter(x=xBasedOnLabel[:, 0], y=xBasedOnLabel[:, 1], c=cmap(idx),\n",
    "                        cmap=plt.cm.coolwarm, marker=markers[idx], label=cl)\n",
    "        plt.xlim(x_x.min(), x_x.max())\n",
    "        plt.ylim(y_y.min(), y_y.max())\n",
    "        plt.xlabel(\"x1\")\n",
    "        plt.ylabel(\"x2\")\n",
    "        plt.title(\"Decision Boundary - Softmax Classifier\")\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Regression() object to load data\n",
    "regr = Regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x after norm:  [[ 1.0787886   0.39156561  1.82696652 ... -0.25536698  0.04263662\n",
      "   1.        ]\n",
      " [ 0.8795134   0.33263061  1.7489647  ...  0.20933975  1.16111646\n",
      "   1.        ]\n",
      " [ 1.24551802  0.59277044  1.3375537  ...  0.10782765 -0.09012211\n",
      "   1.        ]\n",
      " ...\n",
      " [ 0.49275911 -0.33554804 -0.08445636 ... -0.61748968 -0.69887802\n",
      "   1.        ]\n",
      " [-0.12430278  0.20090299 -0.92606031 ...  0.47147596 -0.34367338\n",
      "   1.        ]\n",
      " [ 0.16295868  0.00705689  0.83696937 ...  0.01455268 -0.24641229\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# # load the data\n",
    "# fname = 'YearPredictionMSD.txt'\n",
    "x_train, y_train, x_test, y_test = regr.load_data(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # discuss the properties of the data\n",
    "# x_min = np.min(x_train)\n",
    "# x_max = np.max(x_train)\n",
    "\n",
    "# y_min = np.min(y_train)\n",
    "# y_max = np.max(y_train)\n",
    "\n",
    "\n",
    "# the range of the x feature values is huge, we from -14,000 to 65,000, with a wide\n",
    "# range in scales too, from 1000s to decimals, so we'll need to normalize\n",
    "\n",
    "# for the y labels, it's in years, from 1922-2011, and roughly the same in the test,\n",
    "# though slightly wider range.\n",
    "\n",
    "# The 90's and 2000's are much more over represented than the rest of the \n",
    "# years, expecially the earlier you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = np.linspace(1900, 2020, 20)\n",
    "\n",
    "# plt.hist(y_train, bins, alpha=0.5, label='train')\n",
    "# plt.hist(y_test, bins, alpha=0.5, label='test')\n",
    "# plt.legend(loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  find the most common year (in test data)\n",
    "\n",
    "# years_arr, count = np.unique(y_test, return_counts=True)\n",
    "# year_count_dict = dict(zip(years_arr, count))\n",
    "# # year_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find the loss if every prediction is most commmon \n",
    "# n_samples = x_train.shape[0]\n",
    "# most_common_year = 2007\n",
    "# common_pred = np.full((n_samples, 1), most_common_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_common_loss = regr.musicMSE(common_pred, y_train)\n",
    "# most_common_loss\n",
    "# #  most common year loss = 193.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find loss for 1998\n",
    "# n_samples = x_train.shape[0]\n",
    "# most_common_year = 1998\n",
    "# common_pred = np.full((n_samples, 1), most_common_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_1998 = regr.musicMSE(common_pred, y_train)\n",
    "# loss_1998\n",
    "# #  1998 year loss = 119.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 100...\n",
      "MSE:  116.08668512398276\n",
      "MSE:  114.23218830471585\n",
      "Epoch 2 / 100...\n",
      "MSE:  113.50380454573325\n",
      "MSE:  111.7082311625377\n",
      "Epoch 3 / 100...\n",
      "MSE:  111.55075314669926\n",
      "MSE:  109.8098394039253\n",
      "Epoch 4 / 100...\n",
      "MSE:  110.01220439495486\n",
      "MSE:  108.32168816473967\n",
      "Epoch 5 / 100...\n",
      "MSE:  108.75923314362612\n",
      "MSE:  107.11545337692417\n",
      "Epoch 6 / 100...\n",
      "MSE:  107.71183883650548\n",
      "MSE:  106.11009896758982\n",
      "Epoch 7 / 100...\n",
      "MSE:  106.81760373080951\n",
      "MSE:  105.25388479570103\n",
      "Epoch 8 / 100...\n",
      "MSE:  106.04103427297282\n",
      "MSE:  104.51282644074489\n",
      "Epoch 9 / 100...\n",
      "MSE:  105.3604718450813\n",
      "MSE:  103.8649785166696\n",
      "Epoch 10 / 100...\n",
      "MSE:  104.75802742680874\n",
      "MSE:  103.29235935243233\n",
      "Epoch 11 / 100...\n",
      "MSE:  104.21940886811066\n",
      "MSE:  102.7812248396924\n",
      "Epoch 12 / 100...\n",
      "MSE:  103.73506043732338\n",
      "MSE:  102.32198757331267\n",
      "Epoch 13 / 100...\n",
      "MSE:  103.29699984678918\n",
      "MSE:  101.9066153336562\n",
      "Epoch 14 / 100...\n",
      "MSE:  102.89891725056266\n",
      "MSE:  101.53040242258689\n",
      "Epoch 15 / 100...\n",
      "MSE:  102.5348511927175\n",
      "MSE:  101.18624973939757\n",
      "Epoch 16 / 100...\n",
      "MSE:  102.20130820356016\n",
      "MSE:  100.87148778651594\n",
      "Epoch 17 / 100...\n",
      "MSE:  101.89482265251021\n",
      "MSE:  100.58337391805782\n",
      "Epoch 18 / 100...\n",
      "MSE:  101.61118629881474\n",
      "MSE:  100.31582887688279\n",
      "Epoch 19 / 100...\n",
      "MSE:  101.34867236441545\n",
      "MSE:  100.06852974430481\n",
      "Epoch 20 / 100...\n",
      "MSE:  101.10474376074342\n",
      "MSE:  99.8384753932338\n",
      "Epoch 21 / 100...\n",
      "MSE:  100.87775669832715\n",
      "MSE:  99.62443768134719\n",
      "Epoch 22 / 100...\n",
      "MSE:  100.66560357752535\n",
      "MSE:  99.42479472401746\n",
      "Epoch 23 / 100...\n",
      "MSE:  100.4672710664947\n",
      "MSE:  99.23829623687406\n",
      "Epoch 24 / 100...\n",
      "MSE:  100.28175368079468\n",
      "MSE:  99.06351562881925\n",
      "Epoch 25 / 100...\n",
      "MSE:  100.10752790618959\n",
      "MSE:  98.90017374241553\n",
      "Epoch 26 / 100...\n",
      "MSE:  99.94345980905513\n",
      "MSE:  98.7465743843133\n",
      "Epoch 27 / 100...\n",
      "MSE:  99.7890186949524\n",
      "MSE:  98.60054924601474\n",
      "Epoch 28 / 100...\n",
      "MSE:  99.64331868196685\n",
      "MSE:  98.46361349605839\n",
      "Epoch 29 / 100...\n",
      "MSE:  99.50579915417187\n",
      "MSE:  98.33374089960937\n",
      "Epoch 30 / 100...\n",
      "MSE:  99.37590904253635\n",
      "MSE:  98.21066494450871\n",
      "Epoch 31 / 100...\n",
      "MSE:  99.25264787924174\n",
      "MSE:  98.09485944643058\n",
      "Epoch 32 / 100...\n",
      "MSE:  99.1359505635628\n",
      "MSE:  97.98448144907312\n",
      "Epoch 33 / 100...\n",
      "MSE:  99.02536731043931\n",
      "MSE:  97.88064234561725\n",
      "Epoch 34 / 100...\n",
      "MSE:  98.91986128855284\n",
      "MSE:  97.78203609625794\n",
      "Epoch 35 / 100...\n",
      "MSE:  98.81962203988644\n",
      "MSE:  97.68790409921154\n",
      "Epoch 36 / 100...\n",
      "MSE:  98.72413477098078\n",
      "MSE:  97.59817531117564\n",
      "Epoch 37 / 100...\n",
      "MSE:  98.63361435670456\n",
      "MSE:  97.51204381102114\n",
      "Epoch 38 / 100...\n",
      "MSE:  98.54721066618136\n",
      "MSE:  97.4300700606789\n",
      "Epoch 39 / 100...\n",
      "MSE:  98.46489911245719\n",
      "MSE:  97.35231375499806\n",
      "Epoch 40 / 100...\n",
      "MSE:  98.38610801408407\n",
      "MSE:  97.27772799873591\n",
      "Epoch 41 / 100...\n",
      "MSE:  98.3111235536762\n",
      "MSE:  97.20631422844878\n",
      "Epoch 42 / 100...\n",
      "MSE:  98.23910430376475\n",
      "MSE:  97.1386882134125\n",
      "Epoch 43 / 100...\n",
      "MSE:  98.17068413917528\n",
      "MSE:  97.07360773824928\n",
      "Epoch 44 / 100...\n",
      "MSE:  98.10516039341974\n",
      "MSE:  97.01024422120909\n",
      "Epoch 45 / 100...\n",
      "MSE:  98.0420275830267\n",
      "MSE:  96.95077435463823\n",
      "Epoch 46 / 100...\n",
      "MSE:  97.98220766489082\n",
      "MSE:  96.89367290508049\n",
      "Epoch 47 / 100...\n",
      "MSE:  97.9247598817783\n",
      "MSE:  96.83945293192883\n",
      "Epoch 48 / 100...\n",
      "MSE:  97.86956889717227\n",
      "MSE:  96.78731122075152\n",
      "Epoch 49 / 100...\n",
      "MSE:  97.81672678353637\n",
      "MSE:  96.73673867095691\n",
      "Epoch 50 / 100...\n",
      "MSE:  97.76599877424435\n",
      "MSE:  96.68830362579813\n",
      "Epoch 51 / 100...\n",
      "MSE:  97.7173773251779\n",
      "MSE:  96.64231548900814\n",
      "Epoch 52 / 100...\n",
      "MSE:  97.67084496514508\n",
      "MSE:  96.5978184296306\n",
      "Epoch 53 / 100...\n",
      "MSE:  97.62614669381469\n",
      "MSE:  96.5550998595763\n",
      "Epoch 54 / 100...\n",
      "MSE:  97.58290068461139\n",
      "MSE:  96.5147416169592\n",
      "Epoch 55 / 100...\n",
      "MSE:  97.54139935472915\n",
      "MSE:  96.4753142850909\n",
      "Epoch 56 / 100...\n",
      "MSE:  97.50184291426046\n",
      "MSE:  96.43699949721194\n",
      "Epoch 57 / 100...\n",
      "MSE:  97.46361253456323\n",
      "MSE:  96.400515315546\n",
      "Epoch 58 / 100...\n",
      "MSE:  97.42692267326393\n",
      "MSE:  96.36506341118069\n",
      "Epoch 59 / 100...\n",
      "MSE:  97.391477400803\n",
      "MSE:  96.33157895972253\n",
      "Epoch 60 / 100...\n",
      "MSE:  97.35756486153115\n",
      "MSE:  96.29914953672576\n",
      "Epoch 61 / 100...\n",
      "MSE:  97.32470335065051\n",
      "MSE:  96.26786926344808\n",
      "Epoch 62 / 100...\n",
      "MSE:  97.29294453658268\n",
      "MSE:  96.23721161842272\n",
      "Epoch 63 / 100...\n",
      "MSE:  97.26251020012059\n",
      "MSE:  96.20791937694698\n",
      "Epoch 64 / 100...\n",
      "MSE:  97.2333769324039\n",
      "MSE:  96.17971670262517\n",
      "Epoch 65 / 100...\n",
      "MSE:  97.20531231089544\n",
      "MSE:  96.1531614357826\n",
      "Epoch 66 / 100...\n",
      "MSE:  97.17858254850886\n",
      "MSE:  96.12693887557207\n",
      "Epoch 67 / 100...\n",
      "MSE:  97.15227721751153\n",
      "MSE:  96.10190887121759\n",
      "Epoch 68 / 100...\n",
      "MSE:  97.12727490471546\n",
      "MSE:  96.07706845608611\n",
      "Epoch 69 / 100...\n",
      "MSE:  97.10291830362905\n",
      "MSE:  96.05367298409142\n",
      "Epoch 70 / 100...\n",
      "MSE:  97.07934964856238\n",
      "MSE:  96.03091702870236\n",
      "Epoch 71 / 100...\n",
      "MSE:  97.05650802489437\n",
      "MSE:  96.00936076218575\n",
      "Epoch 72 / 100...\n",
      "MSE:  97.03446691244551\n",
      "MSE:  95.98934998254657\n",
      "Epoch 73 / 100...\n",
      "MSE:  97.01364386543163\n",
      "MSE:  95.96862803677097\n",
      "Epoch 74 / 100...\n",
      "MSE:  96.99320556068801\n",
      "MSE:  95.94857479209324\n",
      "Epoch 75 / 100...\n",
      "MSE:  96.97379726955648\n",
      "MSE:  95.92908197679157\n",
      "Epoch 76 / 100...\n",
      "MSE:  96.9547417285539\n",
      "MSE:  95.91163111971936\n",
      "Epoch 77 / 100...\n",
      "MSE:  96.93593000261602\n",
      "MSE:  95.89441543430276\n",
      "Epoch 78 / 100...\n",
      "MSE:  96.9183962838821\n",
      "MSE:  95.87670853138219\n",
      "Epoch 79 / 100...\n",
      "MSE:  96.90143554981323\n",
      "MSE:  95.86001597067992\n",
      "Epoch 80 / 100...\n",
      "MSE:  96.88459678673058\n",
      "MSE:  95.8441835241008\n",
      "Epoch 81 / 100...\n",
      "MSE:  96.86893763434922\n",
      "MSE:  95.82887085711462\n",
      "Epoch 82 / 100...\n",
      "MSE:  96.85362960511081\n",
      "MSE:  95.81400162949609\n",
      "Epoch 83 / 100...\n",
      "MSE:  96.83890609804655\n",
      "MSE:  95.7996256781096\n",
      "Epoch 84 / 100...\n",
      "MSE:  96.82453562184385\n",
      "MSE:  95.78607090584362\n",
      "Epoch 85 / 100...\n",
      "MSE:  96.81081708779863\n",
      "MSE:  95.77215962207157\n",
      "Epoch 86 / 100...\n",
      "MSE:  96.79753364646939\n",
      "MSE:  95.75879903234909\n",
      "Epoch 87 / 100...\n",
      "MSE:  96.7846452522938\n",
      "MSE:  95.74649378610691\n",
      "Epoch 88 / 100...\n",
      "MSE:  96.77218912647828\n",
      "MSE:  95.7347661961919\n",
      "Epoch 89 / 100...\n",
      "MSE:  96.76000595677195\n",
      "MSE:  95.72389651361843\n",
      "Epoch 90 / 100...\n",
      "MSE:  96.74865787152939\n",
      "MSE:  95.7121209025809\n",
      "Epoch 91 / 100...\n",
      "MSE:  96.73722974514294\n",
      "MSE:  95.7014663381082\n",
      "Epoch 92 / 100...\n",
      "MSE:  96.72642779562825\n",
      "MSE:  95.69052575844746\n",
      "Epoch 93 / 100...\n",
      "MSE:  96.71583299617805\n",
      "MSE:  95.68067670601305\n",
      "Epoch 94 / 100...\n",
      "MSE:  96.7056304917019\n",
      "MSE:  95.67078619462174\n",
      "Epoch 95 / 100...\n",
      "MSE:  96.69555860216236\n",
      "MSE:  95.66123718035476\n",
      "Epoch 96 / 100...\n",
      "MSE:  96.6861110682477\n",
      "MSE:  95.651200830704\n",
      "Epoch 97 / 100...\n",
      "MSE:  96.67706519895326\n",
      "MSE:  95.64229267346941\n",
      "Epoch 98 / 100...\n",
      "MSE:  96.66816891680082\n",
      "MSE:  95.63347338850905\n",
      "Epoch 99 / 100...\n",
      "MSE:  96.65932268414836\n",
      "MSE:  95.62595063257366\n",
      "Epoch 100 / 100...\n",
      "MSE:  96.65098644031154\n",
      "MSE:  95.61793913485498\n"
     ]
    }
   ],
   "source": [
    "# ==========  Ridge Regression Training  =============\n",
    "\n",
    "feat_dims = x_train.shape[1]\n",
    "\n",
    "# create Regression() object to run training\n",
    "regr = Regression(feat_dims)\n",
    "\n",
    "# convert labels to floats\n",
    "y_train = y_train.astype(float)\n",
    "y_test = y_test.astype(float)\n",
    "\n",
    "# sub mean from y labels\n",
    "y_train_sm = regr.label_sub_mean(y_train)\n",
    "y_test_sm = regr.label_sub_mean(y_test)\n",
    "\n",
    "# print('y train', y_train)\n",
    "# print('y sub mean: ', y_train_sm)\n",
    "\n",
    "# train_losses, test_losses = regr.run_epochs(x_train, y_train_sm, x_test, y_test_sm)\n",
    "\n",
    "train_losses, test_losses, train_mse_arr, test_mse_arr, test_preds = regr.run_epochs(x_train, y_train_sm, x_test, y_test_sm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss and accuracies graphs\n",
    "\n",
    "regr.plot_graph(train_losses, test_losses, train_mse_arr, test_mse_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def closed_form(self, x, yt):\n",
    "#     # yt is regular labels\n",
    "#     # returns the weights w that allow you to find the prediction\n",
    "\n",
    "#     xt = np.transpose(x)\n",
    "#     alpha_identity = self.alpha * np.identity(len(xt))\n",
    "\n",
    "\n",
    "#     theInverse = np.linalg.inv(np.dot(xt, x) + alpha_identity)\n",
    "#     w = np.dot(np.dot(theInverse, xt), yt)\n",
    "#     return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.44342442377375"
      ]
     },
     "execution_count": 1209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# closed form solution to ridge regression, obtain w from training data\n",
    "w_closed_form = regr.closed_form(x_train, y_train)\n",
    "\n",
    "# apply w to test data\n",
    "y_pred = np.dot(x_test, w_closed_form)\n",
    "\n",
    "# calc MSE \n",
    "mse_closed_form = regr.musicMSE(y_pred, y_test)\n",
    "mse_closed_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compared to the low of ~95 for the iterative solution I got, the closed form is much lower.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
